# ğŸ§ OpenAI gpt-4o-audio-preview Model Tutorial

## ğŸŒŸ Overview

This repository provides a hands-on tutorial demonstrating how to use OpenAIâ€™s `gpt-4o-audio-preview` model using LangChain. It covers everything from setting up your environment to working with audio inputs and outputs, including advanced use cases like tool calling and task chaining.

Youâ€™ll find practical examples for:
- ğŸ“ **Audio transcription:** Upload audio files and transcribe them using OpenAIâ€™s `gpt-4o-audio-preview` model.
- ğŸ”Š **Audio generation:** Generate spoken responses based on text inputs.
- ğŸ› ï¸ **Advanced tool binding:** Bind external tools, like a weather-fetching function, and integrate them into your workflow.
- ğŸ”— **Task chaining:** Create multi-step workflows that combine tasks, such as transcription followed by tool usage.

## âœ¨ Features
- ğŸ“ **Audio transcription**: Process audio files (e.g., `.wav`) and generate text-based transcriptions.
- ğŸ”Š **Audio generation**: Generate audio responses in formats like `.wav`, with customisable voice options.
- ğŸ› ï¸ **Tool binding**: Integrate external tools to extend the modelâ€™s functionality (e.g., fetching weather data).
- ğŸ”— **Task chaining**: Automate workflows by chaining multiple tasks, combining audio and tool-based functionality.

## âš™ï¸ Prerequisites

To run this project, you will need the following:
- ğŸ Python 3.6+
- ğŸ”‘ OpenAI API key (You can sign up at [OpenAI](https://platform.openai.com/))
- ğŸ“¦ Install the required packages using the provided instructions.

## ğŸ› ï¸ Setup

1. **Clone the repository:**

   ```bash
   git clone https://github.com/anarojoecheburua/OpenAI-gpt-4o-audio-preview-Model-Tutorial.git
   cd your-repo-name
   ```

2. **Set up a virtual environment:**

   ```bash
   python3 -m venv env
   source env/bin/activate  # On Windows use: .\env\Scripts\activate
   ```

3. **Set your OpenAI API Key:**

   You can set your OpenAI API key as an environment variable:

   ```bash
   export OPENAI_API_KEY='your-api-key-here'  # On Windows use: set OPENAI_API_KEY='your-api-key-here'
   ```

   Alternatively, store your API key in a `.env` file and load it in the script.

4. **Run the Jupyter Notebook:**

   ```bash
   jupyter notebook OpenAI_gpt4o_audio_tutorial.ipynb
   ```

## ğŸš€ Usage

- ğŸ“ **Audio Transcription:** Encode your audio files, pass them to the model, and get a transcription as output.
- ğŸ”Š **Audio Generation:** Generate spoken responses by configuring the model with audio output capabilities.
- ğŸ”— **Advanced Workflow:** Chain tasks together, combining transcription and tool usage in a seamless flow.

## â˜• Support My Work
If you found this project helpful and want to support my work, feel free to buy me a coffee! Your support helps me continue creating more tutorials, projects, and open-source contributions like this one. Every coffee is greatly appreciated! ğŸ™Œ
[![Buy Me a Coffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-Support%20Me-orange?logo=buy-me-a-coffee)](https://www.buymeacoffee.com/anarojoecheburua)

